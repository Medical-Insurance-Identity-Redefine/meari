# MEARI

<img src="https://user-images.githubusercontent.com/87626172/131877946-3ad59fb4-c608-45d7-b744-97f6dd0d85fd.png" width="135" align = "left">

```
ğŸ 2021 ë°ì´í„°ì²­ë…„ìº í¼ìŠ¤ <ë¹…ë¦¬ë” ì•„ì¹´ë°ë¯¸> ğŸ

Big Leader Academy
- 2021. 06. 28 ~ 2021. 08. 30

AIë¥¼ í™œìš©í•œ ë¹„ê¸‰ì—¬ ì§„ë£Œë¹„ ìê°€ì ê²€ ì„œë¹„ìŠ¤ğŸ˜Š
```


<br/>

## ëª©ì°¨

- ê°œë°œí™˜ê²½ ë° ì‚¬ìš©í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬

- ì„œë¹„ìŠ¤ workflow

- ê¸°ëŠ¥ ê°œë°œì—¬ë¶€/ë‹´ë‹¹ì

- í•µì‹¬ê¸°ëŠ¥ êµ¬í˜„ ë°©ë²•

- Team_Meari


### ê°œë°œí™˜ê²½ ë° ì‚¬ìš©í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
|                       ë¼ì´ë¸ŒëŸ¬ë¦¬                    |               ëª©ì                  |      
| :------------------------------------------------: | :------------------------------: |
|                        pandas                      |        ë°ì´í„° ë¶„ì„ ë° ì „ì²˜ë¦¬      |
|                       lightgbm                     |           ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸          |
|                       xgboost                      |           ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸          |
|                       catboost                     |           ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸          |
|                       sklearn                      |     ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸, ì„±ëŠ¥ì§€í‘œ ë“±    | 
|                       optuna                       |       í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”       |
|                       pickle                       |   ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ì €ì¥ ë° ë¶ˆëŸ¬ì˜¤ê¸°  |
|                 matplotlib, seaborn                |            ë°ì´í„° ì‹œê°í™”         |
|                       Nanonets                     |              OCR API            |
|                 google cloud vision                |              OCR API            |
|                        openCV                      |              ì˜ìƒì²˜ë¦¬            |
|                      rhinoMorph                    |            í˜•íƒœì†Œë¶„ì„ê¸°          |
<br>

### ì„œë¹„ìŠ¤ workflow
![image](https://user-images.githubusercontent.com/87626172/131874143-de4d3444-1cca-4d11-9b9a-94a83ba880e0.png)


### ê¸°ëŠ¥ ê°œë°œì—¬ë¶€/ë‹´ë‹¹ì

|    ê¸°ìˆ      |        ê¸°ëŠ¥        | ë‹´ë‹¹ì | êµ¬í˜„ ì—¬ë¶€ |
| :---------: | :---------------------: | :----: | :-------: |
|  ë°ì´í„°ì „ì²˜ë¦¬   |        ë°ì´í„°ì •ì œ         |  ì„±í˜„  |     âœ…     |
|  OpenCV + OCR   |        ì„œë¥˜ì½ì–´ì˜¤ê¸°         |  ì£¼ì€  |     âœ…     |
|   NLP    |         ì‚¬ì „ì œì‘          |  ê¸°í‘œ  |     âœ…     |
|  Machine Learning   |        ì˜ˆì¸¡ëª¨ë¸ì œì‘        |  ê·œì˜  |     âœ…     |
|      ì–´í”Œì œì‘       |        í”„ë¡œí† íƒ€ì…         |  ì£¼ì€  |     âœ…     |



### íŒŒíŠ¸ë³„ ì¤‘ìš” ì½”ë“œ
1. EDA

~~~python
le = preprocessing.LabelEncoder()
df_encoded = df

for i in df_encoded.columns[df_encoded.dtypes == 'object']:
    df_encoded[i] = le.fit_transform(list(df_encoded[i]))

def crammersV(var1, var2):
    crosstab = np.array(pd.crosstab(var1, var2, rownames=None, colnames=None))
    stat = chi2_contingency(crosstab)[0]
    obs = np.sum(crosstab)
    mini = min(crosstab.shape) - 1
    return (stat/(obs*mini))

rows = []
for var1 in df_encoded:
    col = []
    for var2 in df_encoded:
        crammers = crammersV(df_encoded[var1], df_encoded[var2])
        col.append(round(crammers,2))
    rows.append(col)

crammers_res = np.array(rows)
df_new = pd.DataFrame(crammers_res, columns=df_encoded.columns, index=df_encoded.columns)
mask = np.zeros_like(df_new, dtype=np.bool)
mask[np.triu_indices_from(mask)] = True

with sns.axes_style('white'):
    plt.rc('font', family='Malgun Gothic')
    ax = sns.heatmap(df_new, mask=mask, vmin=0., vmax=1., square=True, annot=True, cmap='YlGnBu')
plt.show()
   }
   
~~~

2. OpenCV + OCR

~~~python
# testImage ê¸°ì¤€, ìš”ì–‘ê¸°í˜¸ì •ë³´cellëŒ€ë¹„ í™˜ìë“±ë¡ë²ˆí˜¸ cellì˜ í¬ê¸°ëŠ” 0.42ì—ˆìŒ.
# ì‚¬ìš©ìê°€ ì‚¬ì§„ì„ ì°ëŠ” ë°©í–¥ì´ë‚˜ ê°ë„ì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìœ¼ë‹ˆ ì ë‹¹í•œ ë²”ìœ„ë¥¼ ì •í•´ì¤€ë‹¤.
for index , item in enumerate(areaList):
    if 0.3 < pkArea / item < 0.55:
        x = xList[index]
        y = yList[index]
        h = hList[index]
        w = wList[index]

crop_img = image[y:y+h, x:x+w]

#ìš”ì–‘ì •ë³´ cellì˜ ì¹¼ëŸ¼.
cv2.imwrite('hospCode.jpg',crop_img)
hospCode=cv2.imread('hospCode.jpg')
~~~

3. NLP

~~~python
morphed_data_each = rhinoMorph.onlyMorph_list(rn, data_each, pos =['NNG', 'NNP','SL'], eomi = True)
~~~


4. Machine Learning
~~~python
X = df.drop(['í™˜ë¶ˆì—¬ë¶€'], axis=1)
y = df['í™˜ë¶ˆì—¬ë¶€']

def objective(trial):
    # trainê³¼ test split
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

    # oversamplingí•˜ëŠ” ê²½ìš°, train dataì— ëŒ€í•´ì„œ oversamplingí•˜ê¸° 
    # fití•  ë•Œ X_train, y_train ëŒ€ì‹  X_resampled, y_resampledë¡œ ë°”ê¿€ ê²ƒ 
    # X_resampled, y_resampled = sm.fit_resample(X_train, y_train)

    # hyperparameter value í›„ë³´êµ° ì„¤ì •
    param = {
        "objective": "binary",
        "metric": "binary_logloss",
        "verbosity": -1,
        "boosting_type": "gbdt",
        "lambda_l1": trial.suggest_float("lambda_l1", 1e-8, 10.0, log=True),
        "lambda_l2": trial.suggest_float("lambda_l2", 1e-8, 10.0, log=True),
        "num_leaves": trial.suggest_int("num_leaves", 2, 256),
        "feature_fraction": trial.suggest_float("feature_fraction", 0.4, 1.0),
        "bagging_fraction": trial.suggest_float("bagging_fraction", 0.4, 1.0),
        "bagging_freq": trial.suggest_int("bagging_freq", 1, 7),
        "min_child_samples": trial.suggest_int("min_child_samples", 5, 100),
        "learning_rate": trial.suggest_float("learning_rate", 1e-8, 1.0, log=True),
        "n_estimators": trial.suggest_int("n_estimators", 1, 5000)
    }

    model = lgb.LGBMClassifier(**param, boost_from_average = False)
    model.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=200, verbose=False)

    # best thresholdë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•œ ê³¼ì • 
    preds = model.predict_proba(X_test)
    p = preds[:, 1]
    precision, recall, thresholds = precision_recall_curve(y_test, p)

    numerator = 2 * precision * recall
    denom = recall + precision
    fl_scores = np.divide(numerator, denom, out=np.zeros_like(denom), where=(denom!=0))
    max_f1 = np.max(fl_scores)
    max_f1_thresh = thresholds[np.argmax(fl_scores)]

    y_prob_pred = (model.predict_proba(X_test)[:, 1] >= max_f1_thresh).astype(bool)

    print("best threshold : " + str(max_f1_thresh))

    print(classification_report(y_test, y_prob_pred))
    print(confusion_matrix(y_test, y_prob_pred))
    print(accuracy_score(y_test, y_prob_pred))
    print(f1_score(y_test, y_prob_pred))
    print(roc_auc_score(y_test, y_prob_pred))

    return max_f1

# í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”
# objective í•¨ìˆ˜ 100ë²ˆ ì‹¤í–‰
# objective í•¨ìˆ˜ì˜ return valueì¸ f1 scoreê°€ maximizeë˜ë„ë¡ í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ 
study = optuna.create_study(
    pruner = optuna.pruners.MedianPruner(n_startup_trials=5), direction='maximize')

study.optimize(objective, n_trials=100)
~~~


5. Application
~~~swift
func imagePickerController(_ picker: UIImagePickerController, didFinishPickingMediaWithInfo info: [UIImagePickerController.InfoKey : Any]) {
            if let pickedImage = info[.originalImage] as? UIImage {
                    imageView.contentMode = .scaleAspectFit
                    imageView.image = pickedImage
            }
            dismiss(animated: true, completion: nil)
            var sv = UIView()
            sv = UIViewController.displaySpinner(onView: self.view)
            DispatchQueue.main.asyncAfter(deadline: .now() + 3.0) {
                UIViewController.removeSpinner(spinner: sv)
                let alert = UIAlertController(title: "ë¹„ê¸‰ì—¬ ì§„ë£Œë¹„ í™•ì¸ ì„œë¹„ìŠ¤ ëŒ€ìƒì…ë‹ˆë‹¤.", message: """
                    92%ì˜ í™•ë¥ ë¡œ í™˜ë¶ˆì´ ê°€ëŠ¥í•œ í•­ëª©ì…ë‹ˆë‹¤.
                    í•´ë‹¹ ì„œë¹„ìŠ¤ë¥¼ ì‹ ì²­í•˜ì‹œë ¤ë©´ ì„œë¥˜ì œì¶œí•˜ê¸° ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.
                    """, preferredStyle: .alert)
                let defaultAction = UIAlertAction(title: "OK", style: .destructive, handler : nil)
                alert.addAction(defaultAction)
                self.present(alert, animated: true, completion: nil)
            }
            self.submitButton.isHidden = false
        }
~~~

### Jupyter Notebook ì‹¤í–‰ì‹œ ìœ ì˜ ì‚¬í•­
1) run this folderë¥¼ ê·¸ëŒ€ë¡œ ì—…ë¡œë“œ -> Meari_final_code.ipynb ì½”ë“œ ì‹¤í–‰ -> cell -> run all ì‹¤í–‰    
   
2) pip install ~  or import ~ ì˜¤ë¥˜ í•´ê²° ë°©ë²• : package version check -> versionì— ë§ëŠ” package or library download   
   
   
### Team_MEARI

| <IMG src="https://github.com/yooseonghyeon.png?size=100" width="150"> | <IMG src="https://github.com/JubyKim.png?size=100" width="150"> | <IMG src="https://github.com/ilovetayy.png?size=100" width="150">| <IMG src="https://github.com/Giggle1998.png?size=100" width="150">
| :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
|                            ìœ ì„±í˜„                            |                            ê¹€ì£¼ì€                            |                            ì´ê·œì˜                            |                            ì´ê¸°í‘œ                            |

