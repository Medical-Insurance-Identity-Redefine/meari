 precision    recall  f1-score   support

           0       0.94      0.96      0.95     19382
           1       0.82      0.78      0.80      4963

    accuracy                           0.92     24345
   macro avg       0.88      0.87      0.88     24345
weighted avg       0.92      0.92      0.92     24345

[[18559   823]
 [ 1092  3871]]
0.9213390840008215
0.8016982499741121
0.8687548565191934
[I 2021-08-26 16:47:41,627] Trial 36 finished with value: 0.8016982499741121 and parameters: {'lambda_l1': 6.173984951926863e-06, 'lambda_l2': 9.955386221725855e-07, 'num_leaves': 93, 'feature_fraction': 0.6157236879823527, 'bagging_fraction': 0.7899981649056791, 'bagging_freq': 4, 'min_child_samples': 16, 'learning_rate': 0.0578718570843298, 'n_estimators': 2271}. Best is trial 36 with value: 0.8016982499741121.
[LightGBM] [Warning] 